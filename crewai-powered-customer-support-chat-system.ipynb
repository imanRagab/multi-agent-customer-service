{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üõéÔ∏è CrewAI-Powered Customer Support Chat System\n\nThis notebook demonstrates a multi-agent customer support system built using CrewAI.\n\nAgents work together to:\n- Analyze customer inquiries,\n- Route them to the correct specialist,\n- Generate friendly, chat-style responses.\n\nAll conversations are logged automatically for audit and review.","metadata":{}},{"cell_type":"markdown","source":"# üì¶ Libraries Installation and Setup\n\nFirst, we install CrewAI and set up:\n- OpenAI API access\n- Import CrewAI components\n","metadata":{}},{"cell_type":"code","source":"!pip install crewai > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:16:55.602531Z","iopub.execute_input":"2025-04-28T11:16:55.603372Z","iopub.status.idle":"2025-04-28T11:17:00.546519Z","shell.execute_reply.started":"2025-04-28T11:16:55.603340Z","shell.execute_reply":"2025-04-28T11:17:00.545266Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\nuser_secrets = UserSecretsClient()\n\n# Set up OpenAI API key\nos.environ[\"OPENAI_API_KEY\"] = user_secrets.get_secret(\"OPENAI_API_KEY\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.548594Z","iopub.execute_input":"2025-04-28T11:17:00.549083Z","iopub.status.idle":"2025-04-28T11:17:00.676076Z","shell.execute_reply.started":"2025-04-28T11:17:00.549054Z","shell.execute_reply":"2025-04-28T11:17:00.675257Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"# Import CrewAI components\nfrom crewai import Agent, Task, Crew","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.677115Z","iopub.execute_input":"2025-04-28T11:17:00.677683Z","iopub.status.idle":"2025-04-28T11:17:00.681819Z","shell.execute_reply.started":"2025-04-28T11:17:00.677610Z","shell.execute_reply":"2025-04-28T11:17:00.680745Z"}},"outputs":[],"execution_count":114},{"cell_type":"markdown","source":"# üß† Step 1: Agent Design\n\nWe define multiple specialized agents:\n- **Coordinator Agent**: Analyzes user messages and routes to the right specialist.\n- **Order Tracking Agent**: Handles questions about orders and deliveries.\n- **Refund Agent**: Manages refund-related inquiries.\n- **Technical Support Agent**: Assists with technical problems.\n- **Escalation Agent**: Detects sensitive issues and escalates to human support if needed.\n\nEach agent has a specific role and backstory to simulate a real customer support team.","metadata":{}},{"cell_type":"code","source":"# Step 1: Define Specialist Agents\n\n# Specialist Agents\norder_tracking_agent = Agent(\n    name=\"Order Tracking Agent\",\n    role=\"Logistics Specialist\",\n    goal=\"Answer questions about orders, shipping, and deliveries\",\n    backstory=\"Expert in tracking shipments and solving delivery issues.\"\n)\n\nrefund_agent = Agent(\n    name=\"Refund Processing Agent\",\n    role=\"Financial Assistant\",\n    goal=\"Handle customer refund requests quickly and correctly\",\n    backstory=\"Handles financial transactions and refund policies professionally.\"\n)\n\ntechnical_support_agent = Agent(\n    name=\"Technical Support Agent\",\n    role=\"Tech Support Specialist\",\n    goal=\"Solve technical problems customers face with apps or products\",\n    backstory=\"Experienced in troubleshooting software and hardware issues.\"\n)\n\nescalation_agent = Agent(\n    name=\"Escalation Agent\",\n    role=\"Customer Success Manager\",\n    goal=\"Handle complex or emotional customer cases by escalating to a human\",\n    backstory=\"Skilled in managing customer escalations and calming situations.\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.683558Z","iopub.execute_input":"2025-04-28T11:17:00.683817Z","iopub.status.idle":"2025-04-28T11:17:00.704254Z","shell.execute_reply.started":"2025-04-28T11:17:00.683795Z","shell.execute_reply":"2025-04-28T11:17:00.703280Z"}},"outputs":[],"execution_count":115},{"cell_type":"markdown","source":"# üß† Step 2: Define the Coordinator Agent (Decides Which Agent to Assign)\n\nThe **Coordinator Agent** plays a central role in the system.\n\nIts responsibilities:\n- Analyze the latest customer message,\n- Review the conversation history,\n- Decide which specialist agent (Order Tracking, Refund, Technical Support, Escalation) should handle the response.\n\nThe Coordinator Agent:\n- Is designed with a strong background in customer service dispatching,\n- Must respond **with only one word**, indicating the specialist type,\n- Works based on a dynamic task that includes the full conversation history.","metadata":{}},{"cell_type":"code","source":"# Step 2: Define the Coordinator Agent (decides which agent to assign)\n\n# Coordinator Agent\ncoordinator_agent = Agent(\n    name=\"Coordinator Agent\",\n    role=\"Dispatcher\",\n    goal=\"Analyze customer queries and route them to the correct specialist\",\n    backstory=\"Experienced dispatcher who understands how to assign queries efficiently.\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.705282Z","iopub.execute_input":"2025-04-28T11:17:00.705881Z","iopub.status.idle":"2025-04-28T11:17:00.718272Z","shell.execute_reply.started":"2025-04-28T11:17:00.705853Z","shell.execute_reply":"2025-04-28T11:17:00.717207Z"}},"outputs":[],"execution_count":116},{"cell_type":"markdown","source":"# üõ†Ô∏è Step 3: Define Task Templates\n\nWe define two types of tasks in this system:\n\n1. **Coordinator Task**:\n   - The Coordinator Agent reads the current conversation history and the latest user inquiry.\n   - It decides which specialist agent (Order Tracking, Refund, Technical Support, or Escalation) should handle the message.\n   - The Coordinator responds with only one word indicating the routing decision.\n\n2. **Specialist Task**:\n   - The selected Specialist Agent reads the entire conversation context.\n   - It generates a friendly, casual, short reply suitable for live chat support.\n   - The style is informal, avoiding formal email-like structure.\n\nEach task includes:\n- A description of what the agent should do,\n- Clear instructions for the expected output format (e.g., single word for coordinator, short reply for specialist),\n- Context history to ensure continuity and memory across multiple user messages.\n\nBy dynamically creating task descriptions based on live conversation history, the system can maintain natural, coherent dialogues across multiple turns.\n","metadata":{}},{"cell_type":"code","source":"\n# Step 3: Define Task Templates\n\n# Coordinator task: decides the routing\ndef coordinator_task(customer_query):\n    return Task(\n        agent=coordinator_agent,\n        description=(\n            f\"Analyze the following customer query and decide which specialist should handle it:\\n\\n\"\n            f\"'{customer_query}'\\n\\n\"\n            \"Respond ONLY with one word: 'order_tracking', 'refund', 'technical_support', or 'escalation'.\"\n        ),\n        expected_output=\"One of the following words: 'order_tracking', 'refund', 'technical_support', 'escalation'.\"\n    )\n\n# Specialist task: handle the customer case\ndef specialist_task(agent, customer_query):\n    return Task(\n        agent=agent,\n        description=(\n            f\"Professionally handle the following customer query:\\n\\n'{customer_query}'\\n\\n\"\n            \"Provide a clear, polite, and complete response to satisfy the customer.\"\n        ),\n        expected_output=\"A customer-friendly, complete written response that solves the customer's issue.\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.719336Z","iopub.execute_input":"2025-04-28T11:17:00.720035Z","iopub.status.idle":"2025-04-28T11:17:00.732626Z","shell.execute_reply.started":"2025-04-28T11:17:00.720006Z","shell.execute_reply":"2025-04-28T11:17:00.731640Z"}},"outputs":[],"execution_count":117},{"cell_type":"markdown","source":"# üß© Step 4: Define Agent Mapping\n\nOnce we have all the specialist agents defined, we create a **mapping** between the Coordinator's routing decision and the corresponding agent.\n\nThe agent mapping is a simple Python dictionary:\n\n- The **key** is the string decision returned by the Coordinator (e.g., \"order_tracking\", \"refund\", \"technical_support\", or \"escalation\").\n- The **value** is the respective Agent instance that should handle that case.\n\nThis way, when the Coordinator returns a decision word, the system can quickly and automatically select the correct agent without needing complex conditional statements.","metadata":{}},{"cell_type":"code","source":"# Step 4: Define Agent Mapping\n\n# Dictionary for easy specialist selection\nagent_mapping = {\n    \"order_tracking\": order_tracking_agent,\n    \"refund\": refund_agent,\n    \"technical_support\": technical_support_agent,\n    \"escalation\": escalation_agent\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.733490Z","iopub.execute_input":"2025-04-28T11:17:00.733735Z","iopub.status.idle":"2025-04-28T11:17:00.752027Z","shell.execute_reply.started":"2025-04-28T11:17:00.733714Z","shell.execute_reply":"2025-04-28T11:17:00.751205Z"}},"outputs":[],"execution_count":118},{"cell_type":"markdown","source":"# üèóÔ∏è Step 5: Main Execution Function\n\nNow we build the **main function** that handles the full flow for each customer inquiry:\n\n1. **Coordinator Crew Execution**:\n   - The customer‚Äôs latest message, along with the previous chat history, is passed to the Coordinator Agent.\n   - The Coordinator predicts which Specialist Agent should respond.\n\n2. **Routing Decision**:\n   - Based on the Coordinator‚Äôs output (a single keyword like \"order_tracking\" or \"refund\"), \n   - The system uses the agent mapping dictionary to select the appropriate Specialist Agent.\n\n3. **Specialist Crew Execution**:\n   - The Specialist Agent is given the conversation context and the new message.\n   - It generates a friendly, chat-style reply based on the specific issue.\n\n4. **Returning the Response**:\n   - The final specialist agent's output is returned as the assistant‚Äôs message in the conversation.\n","metadata":{}},{"cell_type":"code","source":"# Step 5: Main Execution Function\n\n# Main customer query handling function\ndef handle_customer_query(customer_query):\n    # Step 1: Use the coordinator to decide routing\n    coordinator_crew = Crew(\n        agents=[coordinator_agent],\n        tasks=[coordinator_task(customer_query)]\n    )\n    coordinator_result = coordinator_crew.kickoff()\n\n    decision_text = coordinator_result.tasks_output[0].raw\n    decision = decision_text.lower().strip()\n    print(f\"Coordinator Decision: {decision}\")\n\n    # Step 2: Use the right specialist to answer\n    selected_agent = agent_mapping.get(decision)\n    if not selected_agent:\n        return \"Error: Coordinator couldn't assign the query properly.\"\n\n    specialist_crew = Crew(\n        agents=[selected_agent],\n        tasks=[specialist_task(selected_agent, customer_query)]\n    )\n    \n    response = specialist_crew.kickoff()\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.753152Z","iopub.execute_input":"2025-04-28T11:17:00.753822Z","iopub.status.idle":"2025-04-28T11:17:00.770142Z","shell.execute_reply.started":"2025-04-28T11:17:00.753791Z","shell.execute_reply":"2025-04-28T11:17:00.769102Z"}},"outputs":[],"execution_count":119},{"cell_type":"markdown","source":"# üìù Step 6: Set Up Chat Logging\n\nTo keep a record of the entire customer support conversation, we set up a simple logging mechanism.\n\n### Define a Log File\nWe create (or append to) a text file named `chat_log.txt` to store the conversation.\n","metadata":{}},{"cell_type":"code","source":"# Set a log file\nLOG_FILE = \"chat_log.txt\"\n\n# Helper to save messages to log file\ndef log_conversation(user_message, assistant_message):\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"[{timestamp}] User: {user_message}\\n\")\n        f.write(f\"[{timestamp}] Assistant: {assistant_message}\\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:17:00.771122Z","iopub.execute_input":"2025-04-28T11:17:00.771478Z","iopub.status.idle":"2025-04-28T11:17:00.790358Z","shell.execute_reply.started":"2025-04-28T11:17:00.771450Z","shell.execute_reply":"2025-04-28T11:17:00.789433Z"}},"outputs":[],"execution_count":120},{"cell_type":"markdown","source":"# üîÑ Step 7: Run the Interactive Chat Loop\n\nThis section sets up a **live, interactive chat loop** between the user and the multi-agent CrewAI system.\n\n### Initialize Chat History\nWe initialize an empty list to store the conversation history:\n","metadata":{}},{"cell_type":"code","source":"chat_history = []\n\nprint(\"üëã Welcome to Customer Support Chat!\")\nprint(\"Type your message below. Type 'exit' or 'quit' to leave the conversation.\\n\")\n\nwhile True:\n    customer_query = input(\"üßë You: \")\n\n    if customer_query.lower() in ['exit', 'quit']:\n        print(\"\\nü§ñ Assistant: It was nice helping you! Goodbye! üëã\")\n        break\n\n    # Add the user's inquiry to history\n    chat_history.append(f\"User: {customer_query}\")\n\n    def handle_customer_query_with_memory(customer_query, history):\n        # Prepare conversation history\n        history_text = \"\\n\".join(history)\n\n        # Modify coordinator task to include chat history\n        def coordinator_task_with_memory(customer_query):\n            return Task(\n                agent=coordinator_agent,\n                description=(\n                    f\"You are coordinating a customer support conversation.\\n\\n\"\n                    f\"Conversation so far:\\n{history_text}\\n\\n\"\n                    f\"Customer's latest message:\\n'{customer_query}'\\n\\n\"\n                    f\"Decide who should respond: 'order_tracking', 'refund', 'technical_support', or 'escalation'. \"\n                    f\"Respond with only one word.\"\n                ),\n                expected_output=\"One of: 'order_tracking', 'refund', 'technical_support', 'escalation'.\"\n            )\n\n        def specialist_task_with_memory(agent, customer_query):\n            return Task(\n                agent=agent,\n                description=(\n                    f\"You are chatting casually with a customer.\\n\\n\"\n                    f\"Conversation so far:\\n{history_text}\\n\\n\"\n                    f\"Customer's latest message:\\n'{customer_query}'\\n\\n\"\n                    f\"Reply in a friendly, short, interactive chat style. \"\n                    f\"Avoid formal phrases like 'Dear Customer' or structured emails. \"\n                    f\"Keep it light and natural, like a real human support chat.\"\n                ),\n                expected_output=\"A friendly, informal, short chat-style reply.\"\n            )\n\n        # Routing coordinator\n        coordinator_crew = Crew(\n            agents=[coordinator_agent],\n            tasks=[coordinator_task_with_memory(customer_query)]\n        )\n        coordinator_result = coordinator_crew.kickoff()\n\n        decision_text = coordinator_result.tasks_output[0].raw\n        decision = decision_text.lower().strip()\n\n        selected_agent = agent_mapping.get(decision)\n        if not selected_agent:\n            return \"Error: Could not route the customer request.\"\n\n        specialist_crew = Crew(\n            agents=[selected_agent],\n            tasks=[specialist_task_with_memory(selected_agent, customer_query)]\n        )\n        specialist_result = specialist_crew.kickoff()\n        return specialist_result.tasks_output[0].raw\n\n    # Process inquiry with memory\n    response = handle_customer_query_with_memory(customer_query, chat_history)\n\n    # Add assistant's reply to history\n    chat_history.append(f\"Assistant: {response}\")\n\n    # Save conversation to log file\n    log_conversation(customer_query, response)\n\n    # Final chat output\n    print(f\"ü§ñ Assistant: {response}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T11:23:35.566680Z","iopub.execute_input":"2025-04-28T11:23:35.566996Z","iopub.status.idle":"2025-04-28T11:24:48.577578Z","shell.execute_reply.started":"2025-04-28T11:23:35.566963Z","shell.execute_reply":"2025-04-28T11:24:48.576786Z"}},"outputs":[{"name":"stdout","text":"üëã Welcome to Customer Support Chat!\nType your message below. Type 'exit' or 'quit' to leave the conversation.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üßë You:   My order arrived damaged and it's a supplement. I need a refund\n"},{"name":"stderr","text":"\u001b[92m11:23:47 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:23:47 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n\u001b[92m11:23:47 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:23:49 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n","output_type":"stream"},{"name":"stdout","text":"ü§ñ Assistant: Oh no, I'm really sorry to hear that your order arrived damaged! üòû Let's get that sorted out for you. Can you give me a bit more detail about the damage? Once I have that, I'll process your refund right away!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üßë You:  the inner package is damaged and the pack is open\n"},{"name":"stderr","text":"\u001b[92m11:24:10 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:11 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n\u001b[92m11:24:11 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:13 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n","output_type":"stream"},{"name":"stdout","text":"ü§ñ Assistant: Oh no, that sounds really frustrating! üòî I totally understand why you‚Äôd want a refund for that. Just to speed things up, could you snap a quick pic of the damage? Once I have that, I‚Äôll get your refund processed ASAP! üí™\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üßë You:  I don't have pics\n"},{"name":"stderr","text":"\u001b[92m11:24:25 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:26 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n\u001b[92m11:24:26 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:28 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n","output_type":"stream"},{"name":"stdout","text":"ü§ñ Assistant: No worries at all! I totally understand. We can still help without the pictures. I‚Äôll just need a bit more info ‚Äì like the order number and the details of what‚Äôs wrong with the supplement. Once I have that, I‚Äôll get your refund processed super fast! üôå Let‚Äôs get this sorted out!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üßë You:  7836263\n"},{"name":"stderr","text":"\u001b[92m11:24:35 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:35 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n\u001b[92m11:24:35 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:37 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n","output_type":"stream"},{"name":"stdout","text":"ü§ñ Assistant: Thanks for sharing your order number! üéâ I‚Äôve got all the info I need. I‚Äôll start processing your refund right now, and you should see it back in your account within a few days. If you need anything else or have more questions, just let me know! üòä\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üßë You:  thanks. bye\n"},{"name":"stderr","text":"\u001b[92m11:24:44 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:44 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n\u001b[92m11:24:44 - LiteLLM:INFO\u001b[0m: utils.py:2896 - \nLiteLLM completion() model= gpt-4o-mini; provider = openai\n\u001b[92m11:24:46 - LiteLLM:INFO\u001b[0m: utils.py:1084 - Wrapper: Completed Call, calling success_handler\n","output_type":"stream"},{"name":"stdout","text":"ü§ñ Assistant: You‚Äôre welcome! üòä If you ever need anything else or have more questions down the line, don‚Äôt hesitate to reach out. Take care and have a great day! Bye! üëã\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üßë You:  exit\n"},{"name":"stdout","text":"\nü§ñ Assistant: It was nice helping you! Goodbye! üëã\n","output_type":"stream"}],"execution_count":122},{"cell_type":"markdown","source":"# ‚úÖ Conclusion\n\nThis notebook demonstrates a realistic, CrewAI-powered multi-agent chat system.\n\nKey features:\n- Dynamic agent collaboration.\n- Friendly, real-time conversation.\n- Context retention across multiple user inputs.\n- Conversation logging for records.","metadata":{}}]}